{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learns to solve simple math problems involving two ten-digit numbers.\n",
    "My goal at the beginning was to have it do multiplication.\n",
    "I had problems early on where it refused to converge at all. So I worked forwards starting on really easy problems.\n",
    "It had no trouble converging when the problem was, \"Take the first number and send it back out\". That confirmed that I at\n",
    "least had written the learning and question-generation correctly. I moved up to \"Take the first number and add three\".\n",
    "That worked too. Then I had it add a larger number (which would involve more carrying). I realized that the problem might\n",
    "be that I hadn't given it enough nodes to properly implement the logic. Once I upgraded the network from two 200-node\n",
    "hidden layers to 2000 and 500, it was able to solve the problem of adding the two numbers together with good accuracy. I\n",
    "still haven't gotten it to do multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom layers\n",
    "\n",
    "# This is like the Softmax function, but it does it independently on each digit in the result\n",
    "# So each group of ten nodes should sum up to one\n",
    "class TenSoftmax(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TenSoftmax, self).__init__(**kwargs)\n",
    "        self.softmax = keras.layers.Softmax()\n",
    "    \n",
    "    def call(self, tensor, training=True):\n",
    "        s0, s1, s2, s3, s4, s5, s6, s7, s8, s9 = tf.split(tensor, num_or_size_splits=10, axis=1)\n",
    "        list = [s0, s1, s2, s3, s4, s5, s6, s7, s8, s9]\n",
    "        for i in range(10):\n",
    "            list[i] = self.softmax(list[1])\n",
    "        ret = tf.concat(list, axis=1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def math_model():\n",
    "    # They happen in a linear order\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Input layer / First Hidden Layer\n",
    "    model.add(keras.layers.Dense(2000, input_shape=(200,)))\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    # Second Hidden Layer\n",
    "    model.add(keras.layers.Dense(500))\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(keras.layers.Dense(100))\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "    # model.add(TenSoftmax())\n",
    "    \n",
    "    # Print summary\n",
    "    print(model.summary())\n",
    "\n",
    "    # Return\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "model = math_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "loss_function = tf.keras.losses.MeanSquaredError()    \n",
    "# loss_function = tf.keras.losses.CategoricalCrossentropy()    \n",
    "\n",
    "# Declare optimizer (Use Adam optimizer w/ learning rate of 1e-4)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(count):\n",
    "    input_data, output_data = generate_data(count)\n",
    "    output = model(input_data, training=True)\n",
    "\n",
    "    print(output_data[0])\n",
    "    print(output[0])\n",
    "\n",
    "    # Iterate over answers\n",
    "    correct_answers = 0\n",
    "    wrongness = 0\n",
    "    for yh, y in zip(output, output_data):\n",
    "        yhr = tf.reshape(yh, (10, 10))\n",
    "        yr = tf.reshape(y, (10, 10))\n",
    "        correct = True\n",
    "        for n1, n2 in zip(yhr, yr):\n",
    "            if np.argmax(n1) != np.argmax(n2):\n",
    "                correct = False\n",
    "                break\n",
    "        if correct:\n",
    "            correct_answers += 1\n",
    "\n",
    "    wrongness = loss_function(output, output_data)\n",
    "    \n",
    "    return correct_answers, wrongness\n",
    "\n",
    "def get_digit(number, digit):\n",
    "    number = number % (10**(digit+1))\n",
    "    number = int(number / (10**digit))\n",
    "    return number\n",
    "\n",
    "def digit_vector(num):\n",
    "    e = np.zeros([10])\n",
    "    e[num] = 1\n",
    "    return e\n",
    "\n",
    "def generate_data(data_points):\n",
    "    entries_input = []\n",
    "    entries_output = []\n",
    "    for i in range(data_points):\n",
    "        # Generate numbers\n",
    "        num1 = int(random.random() * 10000000000)\n",
    "        num2 = int(random.random() * 10000000000)\n",
    "        answer = num1 + num2\n",
    "\n",
    "        # print(num1)\n",
    "        # print(num2)\n",
    "        # print(answer)\n",
    "\n",
    "        # Convert to vectors\n",
    "        entry_input = []\n",
    "        for i in range(9, -1, -1):\n",
    "            entry_input.extend(digit_vector(get_digit(num1, i)))\n",
    "        for i in range(9, -1, -1):\n",
    "            entry_input.extend(digit_vector(get_digit(num2, i)))\n",
    "        entry_output = []\n",
    "        for i in range(9, -1, -1):\n",
    "            entry_output.extend(digit_vector(get_digit(answer, i)))\n",
    "        \n",
    "        # Append\n",
    "        entries_input.append(entry_input)\n",
    "        entries_output.append(entry_output)\n",
    "    \n",
    "    ret_input = tf.Variable(entries_input, tf.float64)\n",
    "    ret_output = tf.Variable(entries_output, tf.float64)\n",
    "\n",
    "    # print (ret_input)\n",
    "    # print (ret_output)\n",
    "    \n",
    "    return ret_input, ret_output\n",
    "\n",
    "# generate_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.function annotation causes the function \n",
    "# to be \"compiled\" as part of the training\n",
    "@tf.function\n",
    "def train_step(input_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model(input_data, training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Evaluate\n",
    "    #input_data_test, output_data_test = generate_data(100)\n",
    "    #output = model(input_data_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "  # For each epoch...\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    # For each minibatch...\n",
    "    for _ in range(200):\n",
    "      input_data, output_data = generate_data(100)\n",
    "      train_step(input_data, output_data)\n",
    "\n",
    "    # Print output\n",
    "    print (f\"Epoch {epoch + 1} took {time.time() - start} seconds\")\n",
    "    PROBLEMS = 100\n",
    "    s, w = evaluate(PROBLEMS)\n",
    "    print (f\"Score: {s}/{PROBLEMS}\")\n",
    "    print (f\"Wrongness: {w}\")\n",
    "    print()\n",
    "\n",
    "  \n",
    "train(1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
