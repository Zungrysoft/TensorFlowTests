{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learns to solve simple math problems involving two ten-digit numbers.\n",
    "My goal at the beginning was to have it do multiplication.\n",
    "I had problems early on where it refused to converge at all. So I worked forwards starting on really easy problems.\n",
    "It had no trouble converging when the problem was, \"Take the first number and send it back out\". That confirmed that I at\n",
    "least had written the learning and question-generation correctly. I moved up to \"Take the first number and add three\".\n",
    "That worked too. Then I had it add a larger number (which would involve more carrying). I realized that the problem might\n",
    "be that I hadn't given it enough nodes to properly implement the logic. Once I upgraded the network from two 200-node\n",
    "hidden layers to 2000 and 500, it was able to solve the problem of adding the two numbers together with good accuracy. I\n",
    "still haven't gotten it to do multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_SIZE = 10\n",
    "DIGITS = 4\n",
    "FIRST_LAYER_SIZE = 600\n",
    "EXTRA_LAYER_SIZE = 180\n",
    "EXTRA_LAYERS = DIGITS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom layers\n",
    "\n",
    "# This is like the Softmax function, but it does it independently on each digit in the result\n",
    "# So each group of ten nodes should sum up to one\n",
    "class TenSoftmax(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TenSoftmax, self).__init__(**kwargs)\n",
    "        self.softmax = keras.layers.Softmax()\n",
    "    \n",
    "    def call(self, tensor, training=True):\n",
    "        s0, s1, s2, s3, s4, s5, s6, s7, s8, s9 = tf.split(tensor, num_or_size_splits=10, axis=1)\n",
    "        list = [s0, s1, s2, s3, s4, s5, s6, s7, s8, s9]\n",
    "        for i in range(10):\n",
    "            list[i] = self.softmax(list[1])\n",
    "        ret = tf.concat(list, axis=1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     26\u001b[0m \u001b[39m# Get the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model \u001b[39m=\u001b[39m math_model()\n",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m, in \u001b[0;36mmath_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmath_model\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[39m# They happen in a linear order\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential()\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Input layer / First Hidden Layer\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(FIRST_LAYER_SIZE, input_shape\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m\u001b[39m*\u001b[39mNUM_SIZE,)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "def math_model():\n",
    "    # They happen in a linear order\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Input layer / First Hidden Layer\n",
    "    model.add(keras.layers.Dense(FIRST_LAYER_SIZE, input_shape=(2*10*NUM_SIZE,)))\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    # Carry Layers\n",
    "    for _ in range(EXTRA_LAYERS):\n",
    "        model.add(keras.layers.Dense(EXTRA_LAYER_SIZE))\n",
    "        model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(keras.layers.Dense(10*NUM_SIZE))\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "    # model.add(TenSoftmax())\n",
    "    \n",
    "    # Print summary\n",
    "    print(model.summary())\n",
    "\n",
    "    # Return\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "model = math_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "loss_function = tf.keras.losses.MeanSquaredError()    \n",
    "# loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n",
    "# loss_function = tf.keras.losses.CategoricalCrossentropy()    \n",
    "\n",
    "# Declare optimizer (Use Adam optimizer w/ learning rate of 1e-4)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(count):\n",
    "    input_data, output_data = generate_data(count)\n",
    "    output = model(input_data, training=True)\n",
    "\n",
    "    # Iterate over answers\n",
    "    correct_answers = 0\n",
    "    wrongness = 0\n",
    "    for yh, y in zip(output, output_data):\n",
    "        yhr = tf.reshape(yh, (10, 10))\n",
    "        yr = tf.reshape(y, (10, 10))\n",
    "        correct = True\n",
    "        for n1, n2 in zip(yhr, yr):\n",
    "            if np.argmax(n1) != np.argmax(n2):\n",
    "                correct = False\n",
    "                break\n",
    "        if correct:\n",
    "            correct_answers += 1\n",
    "\n",
    "    wrongness = loss_function(output, output_data)\n",
    "    \n",
    "    return correct_answers, wrongness\n",
    "\n",
    "def get_digit(number, digit):\n",
    "    number = number % (10**(digit+1))\n",
    "    number = int(number / (10**digit))\n",
    "    return number\n",
    "\n",
    "def digit_vector(num):\n",
    "    e = np.zeros([10])\n",
    "    e[num] = 1\n",
    "    return e\n",
    "\n",
    "def generate_data(data_points):\n",
    "    entries_input = []\n",
    "    entries_output = []\n",
    "    for i in range(data_points):\n",
    "        # Generate numbers\n",
    "        scale = 10**DIGITS\n",
    "        num1 = int(random.random() * scale)\n",
    "        num2 = int(random.random() * scale)\n",
    "        answer = num1 + num2\n",
    "\n",
    "        # Convert to vectors\n",
    "        entry_input = []\n",
    "        for i in range(9, -1, -1):\n",
    "            entry_input.extend(digit_vector(get_digit(num1, i)))\n",
    "        for i in range(9, -1, -1):\n",
    "            entry_input.extend(digit_vector(get_digit(num2, i)))\n",
    "        entry_output = []\n",
    "        for i in range(9, -1, -1):\n",
    "            entry_output.extend(digit_vector(get_digit(answer, i)))\n",
    "        \n",
    "        # Append\n",
    "        entries_input.append(entry_input)\n",
    "        entries_output.append(entry_output)\n",
    "    \n",
    "    ret_input = tf.Variable(entries_input, tf.float64)\n",
    "    ret_output = tf.Variable(entries_output, tf.float64)\n",
    "\n",
    "    # print (ret_input)\n",
    "    # print (ret_output)\n",
    "    \n",
    "    return ret_input, ret_output\n",
    "\n",
    "# generate_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.function annotation causes the function \n",
    "# to be \"compiled\" as part of the training\n",
    "@tf.function\n",
    "def train_step(input_data, output_data):\n",
    "    # Set up tape\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = model(input_data, training=True)\n",
    "\n",
    "      loss = loss_function(output_data, output)\n",
    "\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Evaluate\n",
    "    #input_data_test, output_data_test = generate_data(100)\n",
    "    #output = model(input_data_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 0/10\n",
      "Wrongness: 0.036637338304286185\n",
      "\n",
      "Epoch 8: 0/10\n",
      "Wrongness: 0.03529628195212294\n",
      "\n",
      "Epoch 12: 0/10\n",
      "Wrongness: 0.03395851725521704\n",
      "\n",
      "Epoch 16: 0/10\n",
      "Wrongness: 0.03372596880959724\n",
      "\n",
      "Epoch 20: 0/10\n",
      "Wrongness: 0.03223007292006693\n",
      "\n",
      "Epoch 24: 0/10\n",
      "Wrongness: 0.03102924903823953\n",
      "\n",
      "Epoch 28: 0/10\n",
      "Wrongness: 0.030482009556090255\n",
      "\n",
      "Epoch 32: 0/10\n",
      "Wrongness: 0.03128240717828499\n",
      "\n",
      "Epoch 36: 1/10\n",
      "Wrongness: 0.02841051889777852\n",
      "\n",
      "Epoch 40: 0/10\n",
      "Wrongness: 0.02935037409134526\n",
      "\n",
      "Epoch 44: 0/10\n",
      "Wrongness: 0.02854020358016257\n",
      "\n",
      "Epoch 48: 0/10\n",
      "Wrongness: 0.026158784375289477\n",
      "\n",
      "Epoch 52: 1/10\n",
      "Wrongness: 0.023202888185423796\n",
      "\n",
      "Epoch 56: 0/10\n",
      "Wrongness: 0.02492820558475386\n",
      "\n",
      "Epoch 60: 1/10\n",
      "Wrongness: 0.022724786463238132\n",
      "\n",
      "Epoch 64: 0/10\n",
      "Wrongness: 0.020934200986234518\n",
      "\n",
      "Epoch 68: 0/10\n",
      "Wrongness: 0.022403998721786895\n",
      "\n",
      "Epoch 72: 0/10\n",
      "Wrongness: 0.01909672204304344\n",
      "\n",
      "Epoch 76: 3/10\n",
      "Wrongness: 0.017959049943716637\n",
      "\n",
      "Epoch 80: 0/10\n",
      "Wrongness: 0.019147796736703408\n",
      "\n",
      "Epoch 84: 3/10\n",
      "Wrongness: 0.016136533519706526\n",
      "\n",
      "Epoch 88: 2/10\n",
      "Wrongness: 0.017135210152310364\n",
      "\n",
      "Epoch 92: 1/10\n",
      "Wrongness: 0.017360565616990814\n",
      "\n",
      "Epoch 96: 2/10\n",
      "Wrongness: 0.015804368021424778\n",
      "\n",
      "Epoch 100: 3/10\n",
      "Wrongness: 0.015430822325232112\n",
      "\n",
      "Epoch 104: 2/10\n",
      "Wrongness: 0.01562161079958969\n",
      "\n",
      "Epoch 108: 6/10\n",
      "Wrongness: 0.01587797316964027\n",
      "\n",
      "Epoch 112: 1/10\n",
      "Wrongness: 0.015622982691572362\n",
      "\n",
      "Epoch 116: 3/10\n",
      "Wrongness: 0.014843667799471619\n",
      "\n",
      "Epoch 120: 3/10\n",
      "Wrongness: 0.014566083961643961\n",
      "\n",
      "Epoch 124: 1/10\n",
      "Wrongness: 0.016499560853465066\n",
      "\n",
      "Epoch 128: 2/10\n",
      "Wrongness: 0.015750065668853487\n",
      "\n",
      "Epoch 132: 5/10\n",
      "Wrongness: 0.014223296350605801\n",
      "\n",
      "Epoch 136: 5/10\n",
      "Wrongness: 0.013551639155476553\n",
      "\n",
      "Epoch 140: 5/10\n",
      "Wrongness: 0.012148254816999823\n",
      "\n",
      "Epoch 144: 4/10\n",
      "Wrongness: 0.013353378609866923\n",
      "\n",
      "Epoch 148: 4/10\n",
      "Wrongness: 0.013576276171054596\n",
      "\n",
      "Epoch 152: 5/10\n",
      "Wrongness: 0.012655338549152712\n",
      "\n",
      "Epoch 156: 3/10\n",
      "Wrongness: 0.01278726840181087\n",
      "\n",
      "Epoch 160: 1/10\n",
      "Wrongness: 0.01353079936267022\n",
      "\n",
      "Epoch 164: 3/10\n",
      "Wrongness: 0.013172472247296004\n",
      "\n",
      "Epoch 168: 9/10\n",
      "Wrongness: 0.011909178168158252\n",
      "\n",
      "Epoch 172: 6/10\n",
      "Wrongness: 0.01202355124994383\n",
      "\n",
      "Epoch 176: 4/10\n",
      "Wrongness: 0.011977095695311156\n",
      "\n",
      "Epoch 180: 6/10\n",
      "Wrongness: 0.012431488322168564\n",
      "\n",
      "Epoch 184: 4/10\n",
      "Wrongness: 0.012833618186181422\n",
      "\n",
      "Epoch 188: 8/10\n",
      "Wrongness: 0.01111625903769518\n",
      "\n",
      "Epoch 192: 5/10\n",
      "Wrongness: 0.011917601871611703\n",
      "\n",
      "Epoch 196: 7/10\n",
      "Wrongness: 0.011898140455008348\n",
      "\n",
      "Epoch 200: 9/10\n",
      "Wrongness: 0.010546735060774774\n",
      "\n",
      "Epoch 204: 7/10\n",
      "Wrongness: 0.011994932306737111\n",
      "\n",
      "Epoch 208: 8/10\n",
      "Wrongness: 0.010287467349888843\n",
      "\n",
      "Epoch 212: 7/10\n",
      "Wrongness: 0.01093890823895575\n",
      "\n",
      "Epoch 216: 6/10\n",
      "Wrongness: 0.010693991418737812\n",
      "\n",
      "Epoch 220: 9/10\n",
      "Wrongness: 0.010202695374000483\n",
      "\n",
      "Epoch 224: 7/10\n",
      "Wrongness: 0.010453007314380838\n",
      "\n",
      "Epoch 228: 6/10\n",
      "Wrongness: 0.01075902335879094\n",
      "\n",
      "Epoch 232: 8/10\n",
      "Wrongness: 0.009420477630606721\n",
      "\n",
      "Epoch 236: 8/10\n",
      "Wrongness: 0.00937373275911771\n",
      "\n",
      "Epoch 240: 8/10\n",
      "Wrongness: 0.009856474079907678\n",
      "\n",
      "Epoch 244: 9/10\n",
      "Wrongness: 0.009616282681731295\n",
      "\n",
      "Epoch 248: 6/10\n",
      "Wrongness: 0.009604281130308086\n",
      "\n",
      "Epoch 252: 9/10\n",
      "Wrongness: 0.009162807681571197\n",
      "\n",
      "Epoch 256: 8/10\n",
      "Wrongness: 0.00895558840038797\n",
      "\n",
      "Epoch 260: 9/10\n",
      "Wrongness: 0.008435254492066403\n",
      "\n",
      "Epoch 264: 9/10\n",
      "Wrongness: 0.008147616742243426\n",
      "\n",
      "Epoch 268: 9/10\n",
      "Wrongness: 0.007946569308513732\n",
      "\n",
      "Epoch 272: 9/10\n",
      "Wrongness: 0.007606298060652815\n",
      "\n",
      "Epoch 276: 10/10\n",
      "Wrongness: 0.006667515528248397\n",
      "Hit 100% accuracy on 10 problems after 276 epochs!\n",
      "\n",
      "Epoch 290: 90/100\n",
      "Wrongness: 0.006998135195622966\n",
      "\n",
      "Epoch 304: 93/100\n",
      "Wrongness: 0.006432524529773554\n",
      "\n",
      "Epoch 318: 94/100\n",
      "Wrongness: 0.005458876868373835\n",
      "\n",
      "Epoch 331: 96/100\n",
      "Wrongness: 0.004674563334179592\n",
      "\n",
      "Epoch 345: 99/100\n",
      "Wrongness: 0.003922257745007911\n",
      "\n",
      "Epoch 359: 97/100\n",
      "Wrongness: 0.003583950524910528\n",
      "\n",
      "Epoch 373: 100/100\n",
      "Wrongness: 0.003035221556584703\n",
      "Hit 100% accuracy on 100 problems after 373 epochs!\n",
      "\n",
      "Epoch 429: 990/1000\n",
      "Wrongness: 0.0017887581303071335\n",
      "\n",
      "Epoch 480: 1000/1000\n",
      "Wrongness: 0.0009885910535136478\n",
      "Hit 100% accuracy on 1000 problems after 480 epochs!\n",
      "\n",
      "Epoch 705: 9992/10000\n",
      "Wrongness: 0.0004215125574326341\n",
      "\n",
      "Epoch 871: 10000/10000\n",
      "Wrongness: 0.00016576341097054775\n",
      "Hit 100% accuracy on 10000 problems after 871 epochs!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m         seconds_per_test \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m     27\u001b[0m       \u001b[39mprint\u001b[39m()\n\u001b[1;32m---> 30\u001b[0m train(\u001b[39m1000000\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m   \n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m   \u001b[39m# For each minibatch...\u001b[39;00m\n\u001b[0;32m     10\u001b[0m   \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     input_data, output_data \u001b[39m=\u001b[39m generate_data(\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m     train_step(input_data, output_data)\n\u001b[0;32m     14\u001b[0m   \u001b[39m# Test every n seconds\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 57\u001b[0m, in \u001b[0;36mgenerate_data\u001b[1;34m(data_points)\u001b[0m\n\u001b[0;32m     54\u001b[0m     entries_input\u001b[39m.\u001b[39mappend(entry_input)\n\u001b[0;32m     55\u001b[0m     entries_output\u001b[39m.\u001b[39mappend(entry_output)\n\u001b[1;32m---> 57\u001b[0m ret_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mVariable(entries_input, tf\u001b[39m.\u001b[39;49mfloat64)\n\u001b[0;32m     58\u001b[0m ret_output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mVariable(entries_output, tf\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m     60\u001b[0m \u001b[39m# print (ret_input)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m# print (ret_output)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:266\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v1_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    265\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[1;32m--> 266\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:247\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v2_call\u001b[1;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 247\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    248\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m    249\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    250\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    251\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    252\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    253\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m    254\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    255\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m    256\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    257\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    258\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    259\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:240\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v2_call.<locals>.<lambda>\u001b[1;34m(**kws)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v2_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    227\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    228\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    238\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws: default_variable_creator_v2(\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)\n\u001b[0;32m    241\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2755\u001b[0m, in \u001b[0;36mdefault_variable_creator_v2\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2752\u001b[0m aggregation \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39maggregation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   2753\u001b[0m shape \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2755\u001b[0m \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[0;32m   2756\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   2757\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   2758\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   2759\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   2760\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2761\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2762\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   2763\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m   2764\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m   2765\u001b[0m     distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   2766\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   2767\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   2768\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1659\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1656\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[39m=\u001b[39mimport_scope,\n\u001b[0;32m   1657\u001b[0m                         validate_shape\u001b[39m=\u001b[39mvalidate_shape)\n\u001b[0;32m   1658\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1659\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[0;32m   1660\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1661\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   1662\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   1663\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   1664\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1665\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1666\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   1667\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   1668\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   1669\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1670\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   1671\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   1672\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1827\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape)\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1826\u001b[0m     shape \u001b[39m=\u001b[39m initial_value\u001b[39m.\u001b[39mshape\n\u001b[1;32m-> 1827\u001b[0m   handle \u001b[39m=\u001b[39m eager_safe_variable_handle(\n\u001b[0;32m   1828\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1829\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1830\u001b[0m       shared_name\u001b[39m=\u001b[39;49mshared_name,\n\u001b[0;32m   1831\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1832\u001b[0m       graph_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_in_graph_mode)\n\u001b[0;32m   1833\u001b[0m   handle\u001b[39m.\u001b[39m_parent_trackable \u001b[39m=\u001b[39m weakref\u001b[39m.\u001b[39mref(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1834\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:237\u001b[0m, in \u001b[0;36meager_safe_variable_handle\u001b[1;34m(initial_value, shape, shared_name, name, graph_mode)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a variable handle with information to do shape inference.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[39mThe dtype is read from `initial_value` and stored in the returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39m  The handle, a `Tensor` of type `resource`.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m dtype \u001b[39m=\u001b[39m initial_value\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\n\u001b[1;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name,\n\u001b[0;32m    238\u001b[0m                                              graph_mode, initial_value)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:161\u001b[0m, in \u001b[0;36m_variable_handle_from_shape_and_dtype\u001b[1;34m(shape, dtype, shared_name, name, graph_mode, initial_value)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mInternalError(  \u001b[39m# pylint: disable=no-value-for-parameter\u001b[39;00m\n\u001b[0;32m    157\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing an explicit shared_name is not allowed when executing eagerly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n\u001b[0;32m    159\u001b[0m   shared_name \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39manonymous_name()\n\u001b[1;32m--> 161\u001b[0m handle \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mvar_handle_op(\n\u001b[0;32m    162\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    163\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    164\u001b[0m     shared_name\u001b[39m=\u001b[39;49mshared_name,\n\u001b[0;32m    165\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    166\u001b[0m     container\u001b[39m=\u001b[39;49mcontainer)\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m initial_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m   initial_value \u001b[39m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:1226\u001b[0m, in \u001b[0;36mvar_handle_op\u001b[1;34m(dtype, shape, container, shared_name, allowed_devices, name)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   1225\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1226\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   1227\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mVarHandleOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39m\"\u001b[39;49m\u001b[39mcontainer\u001b[39;49m\u001b[39m\"\u001b[39;49m, container, \u001b[39m\"\u001b[39;49m\u001b[39mshared_name\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1228\u001b[0m       shared_name, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype, \u001b[39m\"\u001b[39;49m\u001b[39mshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, shape, \u001b[39m\"\u001b[39;49m\u001b[39mallowed_devices\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1229\u001b[0m       allowed_devices)\n\u001b[0;32m   1230\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   1231\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epochs):\n",
    "  problems = 10\n",
    "  seconds_per_test = 4\n",
    "  last_test = time.time()\n",
    "  # For each epoch...\n",
    "  for epoch in range(epochs):\n",
    "    \n",
    "\n",
    "    # For each minibatch...\n",
    "    for _ in range(100):\n",
    "      input_data, output_data = generate_data(100)\n",
    "      train_step(input_data, output_data)\n",
    "    \n",
    "    # Test every n seconds\n",
    "    if time.time() - last_test >= seconds_per_test:\n",
    "      last_test = time.time()\n",
    "\n",
    "      s, w = evaluate(problems)\n",
    "      print (f\"Epoch {epoch + 1}: {s}/{problems}\")\n",
    "      print (f\"Wrongness: {w}\")\n",
    "\n",
    "      if s == problems:\n",
    "        print(f\"Hit 100% accuracy on {problems} problems after {epoch+1} epochs!\")\n",
    "        problems *= 10\n",
    "        seconds_per_test *= 4\n",
    "\n",
    "      print()\n",
    "\n",
    "  \n",
    "train(1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
