{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_SIZE_O4 = int(IMAGE_SIZE/4)\n",
    "\n",
    "MAX_EPOCHS = 200000\n",
    "BATCH_SIZE = 450\n",
    "\n",
    "NOISE_DIM = 100\n",
    "\n",
    "GENERATOR_LEARNING_RATE = 1e-4\n",
    "DISCRIMINATOR_LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def generator_model():\n",
    "    # They happen in a linear order\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add a NN layer with 7*7*256 nodes and no bias\n",
    "    model.add(keras.layers.Dense(IMAGE_SIZE_O4*IMAGE_SIZE_O4*256, use_bias=False, input_shape=(NOISE_DIM,)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    # Reshape back into a 2D image with 256 layers (and confirm it was reshaped correctly)\n",
    "    model.add(keras.layers.Reshape((IMAGE_SIZE_O4, IMAGE_SIZE_O4, 256)))\n",
    "\n",
    "    # Convolutional layer; ensures that the output will be the same size\n",
    "    model.add(keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    # Another convolutional layer\n",
    "    model.add(keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "    \n",
    "    # Convolution\n",
    "    model.add(keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    \n",
    "    # Print summary?\n",
    "    print(model.summary())\n",
    "\n",
    "    # Return\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "generator = generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates one image from the generator to use as an example\n",
    "def generate_one_image():\n",
    "  noise = tf.random.normal([1, NOISE_DIM])\n",
    "  generated_images = generator(noise, training=False)\n",
    "  return generated_images[0]\n",
    "generate_one_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    # Define model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 1]))\n",
    "    model.add(keras.layers.LeakyReLU()) # ReLU should always come after a convolutional layer\n",
    "    model.add(keras.layers.Dropout(0.3)) # Randomly sets 30% of nodes to 0 during training. Prevents overfitting.\n",
    "\n",
    "    # Another convolution layer, same as above\n",
    "    model.add(keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.LeakyReLU())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    # Flatten to a 1D vector\n",
    "    model.add(keras.layers.Flatten())\n",
    "\n",
    "    # Final step is to convert into a single scalar representing rating\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "discriminator = discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(predicted_output, human_output):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "    return cross_entropy(predicted_output, human_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    # Generator always wants a value of one (which indicates a high rating)\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Declare optimizers\n",
    "# Judge needs a much faster learning rate to make the most of human feedback\n",
    "generator_optimizer = tf.keras.optimizers.Adam(GENERATOR_LEARNING_RATE)\n",
    "judge_optimizer = tf.keras.optimizers.Adam(DISCRIMINATOR_LEARNING_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
